{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TItanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MeanShift,KMeans\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import MeanShift, KMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from ClusteringClassifier import ClusteringClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Co Clare, Ireland Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Whabee, Mrs. George Joseph (Shawneene Abi-Saab)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2688</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Vovk, Mr. Janko</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349252</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>761</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>de Pelsmaeker, Mr. Alfons</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345778</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                             name  \\\n",
       "1216       3         1                               Smyth, Miss. Julia   \n",
       "819        3         1                         Glynn, Miss. Mary Agatha   \n",
       "1286       3         1  Whabee, Mrs. George Joseph (Shawneene Abi-Saab)   \n",
       "1280       3         0                                  Vovk, Mr. Janko   \n",
       "761        3         0                        de Pelsmaeker, Mr. Alfons   \n",
       "\n",
       "         sex   age  sibsp  parch  ticket    fare cabin embarked boat  body  \\\n",
       "1216  female   NaN      0      0  335432  7.7333   NaN        Q   13   NaN   \n",
       "819   female   NaN      0      0  335677  7.7500   NaN        Q   13   NaN   \n",
       "1286  female  38.0      0      0    2688  7.2292   NaN        C    C   NaN   \n",
       "1280    male  22.0      0      0  349252  7.8958   NaN        S  NaN   NaN   \n",
       "761     male  16.0      0      0  345778  9.5000   NaN        S  NaN   NaN   \n",
       "\n",
       "                             home.dest  \n",
       "1216                               NaN  \n",
       "819   Co Clare, Ireland Washington, DC  \n",
       "1286                               NaN  \n",
       "1280                               NaN  \n",
       "761                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_excel(io='titanic.xls')\n",
    "\n",
    "# extract labels\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "# split data on test and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, random_state=42, stratify=y, shuffle=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create useful transformers\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    ''' class to select columns from dataframe '''\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    ''' replace missing values by median '''\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple preprocessing data pipelines without any special feature engineering\n",
    "num_cols = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
    "cat_cols = ['sex', 'embarked', 'home.dest']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selecting_numeric', DataFrameSelector(num_cols) ),\n",
    "    ('missing_data', SimpleImputer(strategy='median') ),\n",
    "    ('normalize', StandardScaler() )\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selecting_categorical', DataFrameSelector(cat_cols) ),\n",
    "    ('missing_data', MostFrequentImputer() ),\n",
    "    ('one_hot_ecoding', OneHotEncoder(sparse = False, handle_unknown='ignore') )\n",
    "])\n",
    "\n",
    "prep_pipeline = FeatureUnion(transformer_list = [\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.82\n",
      "Predicted clusters on test set:\n",
      "[0 1 1 2 2 0 1 1 1 1 2 2 2 1 1 2 2 2 0 2 1 1 3 2 1 2 1 2 2 2 2 1 2 2 2 1 0\n",
      " 3 1 2 2 2 2 2 1 1 2 0 0 2 0 2 3 2 1 1 2 1 3 2 0 2 1 2 0 2 2 2 1 2 1 0 1 2\n",
      " 1 3 2 2 2 2 2 1 2 1 1 3 2 2 2 2 1 2 1 0 2 2 0 2 1 2 2 0 1 2 2 2 2 2 2 0 2\n",
      " 2 0 3 2 2 1 1 2 2 2 2 2 0 2 3 2 2 2 2 0 2 2 2 2 1 1 2 2 2 2 1 1 2 1 2 0 2\n",
      " 1 1 2 2 2 2 2 2 3 2 2 2 0 2 1 2 2 3 2 2 3 2 0 1 2 1 2 0 1 0 2 2 1 0 2 2 2\n",
      " 1 1 0 2 2 1 2 2 2 1 3 1 2 2 2 1 1 1 2 1 0 1 2 0 1 2 2 0 2 1 1 0 1 1 3 0 2\n",
      " 2 3 2 2 1 2 2 2 0 2 2 2 0 2 2 1 1 2 1 1 3 1 2 1 1 0 0 0 1 2 2 2 3 2 1 2 2\n",
      " 0 1 2 2 3 3 3 2 1 2 2 2 2 2 2 1 2 2 2 2 1 1 2 0 1 1 2 2 1 2 1 1 2 2 0 2 2\n",
      " 2 2 2 1 2 2 1 1 2 1 2 2 2 1 2 2 1 2 0 2 2 1 2 2 2 2 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# initialize clustering classifier include two simple models with small hyperparameters optimalization\n",
    "cluster_classifier = ClusteringClassifier(clf_grid_params=[{\n",
    "                                                             'classifier': [LogisticRegression(max_iter=1000)], \n",
    "                                                             'classifier__C': [0.1, 1, 10] \n",
    "                                                            },\n",
    "                                                            {\n",
    "                                                             'classifier': [DecisionTreeClassifier()], \n",
    "                                                             'classifier__max_depth': [3, 5, 10],\n",
    "                                                             'classifier__min_samples_split': [2, 4, 6]\n",
    "                                                            }],\n",
    "                                           clt = KMeans,\n",
    "                                           clt_params={'n_clusters':4} )\n",
    "\n",
    "# create final pipeline inluding classification\n",
    "pipe = Pipeline(\n",
    "                     [\n",
    "                         ('prep', prep_pipeline),\n",
    "                         ('cluster_classifier', cluster_classifier )\n",
    "                     ]\n",
    ")\n",
    "\n",
    "# fit pipeline\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# show accuracy on test set\n",
    "y_pred = pipe.predict(X_test)[0] \n",
    "print(f'Accuracy on test set: {round(metrics.accuracy_score(y_test,y_pred),2)}')\n",
    "\n",
    "# show prdicted clusters on test set\n",
    "print(f'Predicted clusters on test set:\\n{pipe.predict(X_test)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1: LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "-------------------------------------------------------------------------------------\n",
      "Cluster2: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "-------------------------------------------------------------------------------------\n",
      "Cluster3: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "-------------------------------------------------------------------------------------\n",
      "Cluster4: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# extract classifier from pipeline\n",
    "model=pipe.steps[1][1]\n",
    "\n",
    "# show models for each cluster\n",
    "for i,clf in enumerate(model.clf_models, 1):\n",
    "    try:\n",
    "        print(f'Cluster{i}: {clf.steps[0][1]}')\n",
    "    except AttributeError: # if classifier is OneClassClassifier\n",
    "        print(f'Cluster{i}: {clf.__class__.__name__}')    \n",
    "    print('-'*85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
